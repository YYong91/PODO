from voice.hotword import wait_for_hotword
from voice.input import listen_until_silence
from voice.output import speak
from gpt.handler import analyze_user_input, summarize_logs
from storage.db import init_db, save_log, get_recent_logs
from openai import OpenAI

print("ğŸ§ í¬ë„ì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤! ê°€ë³ê²Œ ë§ ê±¸ì–´ë³´ì„¸ìš”.")
init_db()
client = OpenAI()

while True:
    wait_for_hotword()  # ğŸ”” "í¬ë„ì•¼" ê°ì§€ë˜ë©´ ë‹¤ìŒ ì§„í–‰

    audio_buffer = listen_until_silence()
    if audio_buffer is None:
        continue

    text = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_buffer
    ).text

    print(f"ğŸ“ ì¸ì‹ëœ ë§: {text}")

    if not text.strip():
        continue

    if any(kw in text for kw in ["ëë‚¼ê²Œ", "ì—¬ê¸°ê¹Œì§€ ë§ˆë¬´ë¦¬"]):
        speak("ì˜¤ëŠ˜ë„ ìˆ˜ê³  ë§ìœ¼ì…¨ì–´ìš”. ë‹¤ìŒì— ë˜ ì´ì•¼ê¸°í•´ìš” ğŸ˜Š")
        break

    if any(kw in text for kw in ["ì´ë²ˆ ì£¼ ìš”ì•½", "ìµœê·¼ ê¸°ë¡", "ì¼ì£¼ì¼ ì •ë¦¬"]):
        summaries = get_recent_logs(days=7)
        summary_text = summarize_logs(summaries)
        speak(summary_text)
        continue

    result = analyze_user_input(text)
    speak(f"ê¸°ë¡í• ê²Œìš”. {result['response']}" if result["should_save"] == "YES" else result["response"])

    if result["should_save"] == "YES":
        save_log(
            raw_text=text,
            summary=result["summary"],
            tags=result.get("tags", []),
            mood=result.get("mood", [])
        )
        print(f"ğŸ“Œ ê¸°ë¡ ì €ì¥ë¨: {result['summary']} | íƒœê·¸: {result['tags']} | ë¶„ìœ„ê¸°: {result['mood']}")
    else:
        print("ğŸ“ ì¼ë°˜ ëŒ€í™”ë¡œ ì €ì¥í•˜ì§€ ì•Šì•˜ì–´ìš”.")
